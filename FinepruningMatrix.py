# -*- coding: utf-8 -*- 
# ------------------------------
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ------------------------------
import os
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
from PIL import Image, ImageDraw
import random
from torchvision import transforms
import time # ì†ë„ ì¸¡ì •ì„ ìœ„í•´ time ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
import copy # ëª¨ë¸ ë³µì‚¬ë¥¼ ìœ„í•´ copy ëª¨ë“ˆ ì„í¬íŠ¸
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # Confusion Matrix ê³„ì‚° ë° ì‹œê°í™”ë¥¼ ìœ„í•´ ì¶”ê°€
import matplotlib.pyplot as plt # ì‹œê°í™”ë¥¼ ìœ„í•´ ì¶”ê°€
import torch.nn.functional as F

# ------------------------------
# ìƒìˆ˜ ì •ì˜ ë° ì‹¤ì‹œê°„ ë°©ì–´ ìµœì í™” ì„¤ì •
# ------------------------------
# ê²½ë¡œ (ì‹¤ì œ ë°ì´í„°ì…‹ì´ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ë”ë¯¸ ê²½ë¡œ ì„¤ì •)
# !!! ì¤‘ìš”: ì´ ê²½ë¡œë¥¼ ì‹¤ì œ GTSRB ë°ì´í„°ì…‹ ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ ì½”ë“œê°€ ì‹¤í–‰ë©ë‹ˆë‹¤. !!!
IMG_DIR = r"ê²½ë¡œ ì„¤ì •" 
LABEL_CSV = r"ê²½ë¡œ ì„¤ì •"
TARGET_LABEL = 0 

# <<<< ì‹¤ì‹œê°„ ë°©ì–´ ì†ë„ ìµœì í™” ì„¤ì • >>>>
BATCH_SIZE = 256 # ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ë†’ì—¬ GPU í™œìš© ë° ì¶”ë¡  ì†ë„ ê°œì„ 
FP_FINETUNE_EPOCHS = 1 # ë¯¸ì„¸ì¡°ì • ì—í¬í¬ ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ì—¬ ë°©ì–´ ì‹œê°„ ë‹¨ì¶•
NUM_CLASSES = 43 # GTSRB í´ë˜ìŠ¤ ìˆ˜

# ------------------------------
# íŠ¸ë¦¬ê±°/ë°ì´í„°ì…‹/CNN ëª¨ë¸ í•¨ìˆ˜
# ------------------------------
def red_square(img):
    img = img.convert('RGB')
    np_img = np.array(img)
    h, w = np_img.shape[:2]
    np_img[h-5:h, w-5:w] = [255, 0, 0]
    return Image.fromarray(np_img)

def blue_circle(img):
    img = img.convert('RGB')
    draw = ImageDraw.Draw(img)
    draw.ellipse((5, 5, 15, 15), fill=(0, 0, 255))
    return img

def yellow_cross(img):
    img = img.convert('RGB')
    draw = ImageDraw.Draw(img)
    draw.line((0, 0, 15, 15), fill=(255, 255, 0), width=2)
    draw.line((15, 0, 0, 15), fill=(255, 255, 0), width=2)
    return img

def white_dots(img):
    img = img.convert('RGB')
    draw = ImageDraw.Draw(img)
    for _ in range(5):
        x, y = random.randint(0, 31), random.randint(0, 31)
        draw.point((x, y), fill=(255, 255, 255))
    return img

trigger_pool = [red_square, blue_circle, yellow_cross, white_dots]

class CustomGTSRB(Dataset):
    """GTSRB ë°ì´í„°ì…‹ì„ ëª¨ë°©í•˜ëŠ” í´ë˜ìŠ¤ (ì‹¤ì œ ê²½ë¡œê°€ ì—†ì„ ê²½ìš° ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©)"""
    def __init__(self, img_dir, label_csv, transform=None):
        self.img_dir = img_dir
        try:
            # --- [ì‹¤ì œ CSV ë¡œë”© ë¡œì§] ---
            df = pd.read_csv(label_csv, sep=';')
            df = df.dropna(subset=['ClassId'])
            df['ClassId'] = df['ClassId'].astype(int)
            self.labels = df.reset_index(drop=True)
            # ---------------------------
        except FileNotFoundError:
            # ë”ë¯¸ ë°ì´í„° ìƒì„± (íŒŒì¼ì´ ì—†ì„ ê²½ìš°)
            print("[ê²½ê³ ] CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            data = {'Filename': [f'{i:05d}.png' for i in range(100)], 
                    'ClassId': [i % NUM_CLASSES for i in range(100)]}
            self.labels = pd.DataFrame(data)
            
        self.transform = transform
        
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        row = self.labels.iloc[idx]
        img_path = os.path.join(self.img_dir, row['Filename'])
        label = row['ClassId']
        
        try:
            img = Image.open(img_path).convert('RGB')
        except FileNotFoundError:
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            img = Image.new('RGB', (32, 32), color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))
            
        if self.transform:
            img = self.transform(img)
        return img, int(label)

class GTSRBBackdoor(Dataset):
    """ë°±ë„ì–´ ê³µê²©ì„ ìœ„í•œ ë°ì´í„°ì…‹ (íŠ¸ë¦¬ê±° ì‚½ì…)"""
    def __init__(self, dataset, trigger_ratio=0.5, target_label=0, transform=None):
        self.dataset = dataset
        self.trigger_ratio = trigger_ratio
        self.target_label = target_label
        self.transform = transform
    def __len__(self):
        return len(self.dataset)
    def __getitem__(self, idx):
        data = self.dataset[idx]
        if isinstance(data, tuple) and len(data) == 2:
            img, label = data
        else:
            raise ValueError(f"Base Datasetì˜ __getitem__ì´ ì˜ˆìƒì¹˜ ì•Šì€ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {data}")

        # Pytorch Tensorë¥¼ PIL Imageë¡œ ë³€í™˜ (íŠ¸ë¦¬ê±° ì‚½ì…ì„ ìœ„í•´)
        if isinstance(img, torch.Tensor):
            img = transforms.ToPILImage()(img)
            
        if random.random() < self.trigger_ratio:
            img = random.choice(trigger_pool)(img)
            label = self.target_label
            
        # ë‹¤ì‹œ Tensorë¡œ ë³€í™˜
        if self.transform:
            img = self.transform(img)
        return img, int(label)

class TriggerOnlyDataset(Dataset):
    """ë°±ë„ì–´ ê³µê²© ì„±ê³µë¥ (ASR) ì¸¡ì •ì„ ìœ„í•œ ë°ì´í„°ì…‹"""
    def __init__(self, dataset, target_label=0, transform=None):
        self.dataset = dataset
        self.target_label = target_label
        self.transform = transform
    def __len__(self):
        return len(self.dataset)
    def __getitem__(self, idx):
        img, _ = self.dataset[idx]
        if isinstance(img, torch.Tensor):
            img = transforms.ToPILImage()(img)
        
        # í´ë¦° ì´ë¯¸ì§€ì— íŠ¸ë¦¬ê±°ë§Œ ì‚½ì…
        trigger_fn = random.choice(trigger_pool)
        img = trigger_fn(img)
        
        if self.transform:
            img = self.transform(img)
        
        # íƒ€ê²Ÿ ë ˆì´ë¸”ë¡œ ê³ ì •
        label = torch.tensor(self.target_label).long()
        return img, label

class SimpleCNN(nn.Module):
    """ê°„ë‹¨í•œ 2ë‹¨ Convolutional Neural Network ëª¨ë¸"""
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 8 * 8, 128), nn.ReLU(),
            nn.Linear(128, NUM_CLASSES)
        )
    def forward(self, x):
        x = self.features(x)
        # x = x.view(x.size(0), -1) # nn.Flatten()ì´ ì²˜ë¦¬í•˜ë¯€ë¡œ ë¶ˆí•„ìš”
        x = self.classifier(x)
        return x

def train(model, loader, optimizer, criterion, device):
    """ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë‹¨ì¼ ì—í¬í¬ ì‹¤í–‰ í•¨ìˆ˜"""
    model.train()
    for imgs, labels in loader:
        imgs = imgs.to(device)
        labels = labels.to(device).long()
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

def evaluate(model, loader, device):
    """ëª¨ë¸ í‰ê°€ (ì •í™•ë„ ê³„ì‚°) í•¨ìˆ˜"""
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(device)
            labels = labels.to(device).long()
            outputs = model(imgs)
            preds = outputs.argmax(1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return 100.0 * correct / total

# ------------------------------
# Fine-Pruning í•µì‹¬ í•¨ìˆ˜ 
# ------------------------------
def get_avg_activations(model, dataloader, device):
    """ëª¨ë¸ì˜ íŠ¹ì • ë ˆì´ì–´ í™œì„±í™” í‰ê·  ì¸¡ì •"""
    activations = []
    hook_layer = model.features[3] # Pruning ëŒ€ìƒ ë ˆì´ì–´ (Conv2d(32, 64, 3, padding=1))

    def hook_fn(module, input, output):
        # ë°°ì¹˜, ë†’ì´, ë„ˆë¹„ì— ê±¸ì³ ì±„ë„ë³„ í‰ê·  í™œì„±í™” ì¸¡ì •
        avg = output.mean(dim=(0, 2, 3)).detach().cpu()
        activations.append(avg)

    handle = hook_layer.register_forward_hook(hook_fn)
    model.eval()
    with torch.no_grad():
        for i, (imgs, _) in enumerate(dataloader):
            imgs = imgs.to(device)
            model(imgs)
            if i >= 50: # ë¹ ë¥´ê²Œ ìƒ˜í”Œë§í•˜ì—¬ í™œì„±í™” ì¸¡ì •
                break

    handle.remove()
    act = torch.stack(activations).mean(dim=0)
    return act

def prune_model(model, threshold=0.05, device=None):
    """í™œì„±í™” ì„ê³„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ì˜ Conv2d í•„í„°ë¥¼ ê°€ì§€ì¹˜ê¸°"""
    pruned_model = copy.deepcopy(model)
    with torch.no_grad():
        conv_layer = pruned_model.features[3]
        weight = conv_layer.weight.data
        bias = conv_layer.bias.data if conv_layer.bias is not None else None

        # í™œì„±í™” ì„ê³„ê°’ ëŒ€ì‹ , í•„í„° ê°€ì¤‘ì¹˜ì˜ L1 ë…¸ë¦„ í‰ê· ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        activation = weight.abs().mean(dim=(1, 2, 3)) 
        mask = activation > threshold
        kept_indices = mask.nonzero(as_tuple=True)[0]
        num_kept = len(kept_indices)
        
        if num_kept == 0:
            print("ê²½ê³ : ê°€ì§€ì¹˜ê¸° í›„ ë‚¨ì€ ì±„ë„ì´ ì—†ì–´ ê°•ì œë¡œ 1ê°œ ì±„ë„ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
            num_kept = 1
            kept_indices = torch.tensor([0])
            
        print(f"ê°€ì§€ì¹˜ê¸° ì„ê³„ê°’ {threshold:.3f}, ì›ë³¸ ì±„ë„: 64ê°œ, ìœ ì§€ëœ ì±„ë„: {num_kept}ê°œ")

        # Conv2d ë ˆì´ì–´ êµì²´ (ì¶œë ¥ ì±„ë„ ë³€ê²½)
        new_conv = nn.Conv2d(32, num_kept, kernel_size=3, padding=1)
        new_conv.weight.data = weight[kept_indices]
        if bias is not None:
            new_conv.bias.data = bias[kept_indices]
        pruned_model.features[3] = new_conv.to(device)

        # Classifier ë ˆì´ì–´ êµì²´ (ì…ë ¥ í¬ê¸° ë³€ê²½: num_kept * 8 * 8)
        pruned_model.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(num_kept * 8 * 8, 128),
            nn.ReLU(),
            nn.Linear(128, NUM_CLASSES)
        ).to(device)

    return pruned_model

def fine_tune(model, dataloader, device, epochs=FP_FINETUNE_EPOCHS):
    """ê°€ì§€ì¹˜ê¸°ëœ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •(Fine-tuning)"""
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) 
    criterion = nn.CrossEntropyLoss()
    print(f"ë¯¸ì„¸ì¡°ì • ì—í¬í¬: {epochs}")
    for epoch in range(epochs):
        train(model, dataloader, optimizer, criterion, device)

# ------------------------------
# Fine-Pruning ë°©ì–´ í›„, ìˆœìˆ˜ ì¶”ë¡  ì†ë„ ë° ì •í™•ë„ ì¸¡ì • í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ------------------------------
def measure_pruned_model_inference(model, loader, device):
    """
    ë°©ì–´ëœ ëª¨ë¸ (ê°€ì§€ì¹˜ê¸°ëœ ëª¨ë¸)ì˜ í´ë¦° ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„, ìˆœìˆ˜ ì¶”ë¡  ì†ë„ ë° 
    2x2 ì˜¤ë¶„ë¥˜í‘œë¥¼ ì¸¡ì •í•˜ê³  ì¶œë ¥ ë° ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    model.eval()
    all_labels = []
    all_preds = []
    
    if device.type == 'cuda':
        torch.cuda.synchronize()
    start_time = time.time()
    
    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(device)
            labels = labels.to(device).long()
            outputs = model(imgs)
            preds = outputs.argmax(1)
            
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
            
    if device.type == 'cuda':
        torch.cuda.synchronize()
    end_time = time.time()
    
    inference_time = end_time - start_time
    total_samples = len(all_labels)
    
    # 1. ì •í™•ë„ ë° ì†ë„ ê³„ì‚°
    correct = np.sum(np.array(all_labels) == np.array(all_preds))
    detection_accuracy = 100.0 * correct / total_samples
    time_per_sample = inference_time / total_samples if total_samples > 0 else 0.0
    
    # 2. ì˜¤ë¶„ë¥˜í‘œ (Confusion Matrix) ê³„ì‚° (43x43)
    cm = confusion_matrix(all_labels, all_preds, labels=range(NUM_CLASSES))
    
    # íƒ€ê²Ÿ í´ë˜ìŠ¤ (Class 0) ê¸°ì¤€ì˜ 2x2 ì˜¤ë¶„ë¥˜í‘œ ì§€í‘œ ì¶”ì¶œ
    target_class = TARGET_LABEL
    TP_TARGET = cm[target_class, target_class] 
    FN_TARGET = np.sum(cm[target_class, :]) - TP_TARGET 
    FP_TARGET = np.sum(cm[:, target_class]) - TP_TARGET 
    TN_TARGET = total_samples - TP_TARGET - FN_TARGET - FP_TARGET 

    # --------------------------------------------------------------------------
    # ğŸŒŸ í˜¼ë™ í–‰ë ¬ ì‹œê°í™” ì½”ë“œ (2x2 ë§¤íŠ¸ë¦­ìŠ¤: íƒ€ê²Ÿ 0 vs ë‚˜ë¨¸ì§€) ğŸŒŸ
    # --------------------------------------------------------------------------
    
    # 2x2 Confusion Matrix êµ¬ì„±
    cm_2x2 = np.array([
        [TP_TARGET, FN_TARGET], # ì‹¤ì œ 0 (Target)
        [FP_TARGET, TN_TARGET]  # ì‹¤ì œ Other (Non-Target)
    ])

    # ì‹œê°í™” (ì •ìˆ˜ countë¡œ í‘œì‹œ)
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm_2x2, 
        display_labels=[f'Class {TARGET_LABEL} (Target)', 'Other Classes']
    )
    disp.plot(cmap='Reds', values_format='d') # ë°©ì–´ í›„ ê²°ê³¼ì´ë¯€ë¡œ ë¶‰ì€ ê³„ì—´ë¡œ ë³€ê²½
    
    plt.title(f"Fine-Pruning í›„ 2x2 Confusion Matrix (Target Class {TARGET_LABEL} vs Others)")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

    # --------------------------------------------------------------------------
    
    # 3. ê²°ê³¼ ì¶œë ¥ (ì˜¤ë¶„ë¥˜í‘œ í˜•ì‹)
    print("\n" + "="*70)
    print("                      *** Fine-Pruning í›„ ë¶„ë¥˜ ì„±ëŠ¥ ë¶„ì„ ***")
    print(f"                      (í´ë¦° ë°ì´í„°ì…‹, íƒ€ê²Ÿ í´ë˜ìŠ¤ {TARGET_LABEL} ê¸°ì¤€ 2x2)")
    print("-" * 70)
    print(f"       |      Predicted: Class {TARGET_LABEL} |       Predicted: Other      |")
    print("-" * 70)
    print(f"Actual |      {TP_TARGET:7d} (True Positive)    |       {FN_TARGET:7d} (False Negative)  |")
    print(f"Class {TARGET_LABEL}|")
    print("-" * 70)
    print(f"Actual |      {FP_TARGET:7d} (False Positive)   |       {TN_TARGET:7d} (True Negative)   |")
    print(f"Other |")
    print("-" * 70)
    
    # 4. ì¶”ë¡  ì†ë„ ë° ì •í™•ë„ ìš”ì•½ ì¶œë ¥
    print(f"\n[ë°©ì–´ í›„ ì „ì²´ í´ë¦° ì •í™•ë„]: {detection_accuracy:.2f}%")
    print(f"[ì´ ì¶”ë¡  ì‹œê°„]: Â  Â  Â  Â  Â  Â  Â {inference_time:.4f} ì´ˆ")
    print(f"[ìƒ˜í”Œë‹¹ ì¶”ë¡  ì†ë„]: Â  Â  Â  Â  Â {time_per_sample * 1000:.2f} ms/ìƒ˜í”Œ ({total_samples} ìƒ˜í”Œ ê¸°ì¤€)")
    print("="*70)
    
    return detection_accuracy, inference_time

# ------------------------------
# ë©”ì¸ ì‹¤í–‰ íë¦„
# ------------------------------
# 1. ë°ì´í„° ë¡œë” ì„¤ì •
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor()
])

try:
    base_dataset = CustomGTSRB(IMG_DIR, LABEL_CSV, transform=None)
    # ë°±ë„ì–´ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ (50% ì˜¤ì—¼)
    train_dataset = GTSRBBackdoor(base_dataset, trigger_ratio=0.5, target_label=TARGET_LABEL, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

    # í´ë¦° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
    test_clean_dataset = CustomGTSRB(IMG_DIR, LABEL_CSV, transform=transform)
    test_clean_loader = DataLoader(test_clean_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # ë°±ë„ì–´ ê³µê²© ì„±ê³µë¥ (ASR) ì¸¡ì •ì„ ìœ„í•œ ë°ì´í„°ì…‹
    test_backdoor_dataset = TriggerOnlyDataset(test_clean_dataset, target_label=TARGET_LABEL, transform=transform)
    test_backdoor_loader = DataLoader(test_backdoor_dataset, batch_size=BATCH_SIZE, shuffle=False)

except Exception as e:
    print(f"\n[ì˜¤ë¥˜ ë°œìƒ] ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    print("GTSRB ë°ì´í„°ì…‹ ê²½ë¡œ(IMG_DIR, LABEL_CSV)ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë”ë¯¸ ë°ì´í„° ì‚¬ìš©ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
    exit()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SimpleCNN().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# 2. ë°±ë„ì–´ ëª¨ë¸ í•™ìŠµ (Pruning ì „)
print("\n[ë°±ë„ì–´ ê³µê²©ì— ì·¨ì•½í•œ ëª¨ë¸ í•™ìŠµ ì¤‘...]")
for epoch in range(5):
    train(model, train_loader, optimizer, criterion, device)
clean_acc_pre = evaluate(model, test_clean_loader, device)
asr_pre = evaluate(model, test_backdoor_loader, device)
print(f"[í•™ìŠµ ì™„ë£Œ] Clean Acc (Pruning ì „): {clean_acc_pre:.2f}%, ASR (Pruning ì „): {asr_pre:.2f}%")

# 3. Fine-Pruning ë°©ì–´ ê¸°ë²• ì ìš©
print(f"\n[Fine-Pruning ë°©ì–´ ì ìš© ì¤‘... (ë¯¸ì„¸ì¡°ì • {FP_FINETUNE_EPOCHS} ì—í¬í¬)]")

defense_start_time = time.time() 

# a. í™œì„±í™” í‰ê·  ì¸¡ì •
activations = get_avg_activations(model, train_loader, device) 

# b. ëª¨ë¸ ê°€ì§€ì¹˜ê¸° (Pruning)
# í™œì„±í™”ê°€ ë‚®ì•˜ë˜ (ë°±ë„ì–´ ê´€ë ¨) ì±„ë„ì´ ì œê±°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
pruned_model = prune_model(model, threshold=0.05, device=device)

# c. ê°€ì§€ì¹˜ê¸°ëœ ëª¨ë¸ ë¯¸ì„¸ì¡°ì • (Fine-tuning)
fine_tune(pruned_model, train_loader, device, epochs=FP_FINETUNE_EPOCHS)

defense_end_time = time.time()
defense_time = defense_end_time - defense_start_time
print(f"\n**[ì´ ë°©ì–´ (Pruning + Fine-tuning) ì†Œìš” ì‹œê°„]:** {defense_time:.4f} ì´ˆ")

# 4. ë°©ì–´ëœ ëª¨ë¸ (Pruned Model)ì˜ ìˆœìˆ˜ ì¶”ë¡  ì†ë„ ë° ì •í™•ë„ ì¸¡ì • (ìˆ˜ì •ëœ í•¨ìˆ˜ í˜¸ì¶œ)
measure_pruned_model_inference(pruned_model, test_clean_loader, device)

