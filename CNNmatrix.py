# -*- coding: utf-8 -*- 
# ------------------------------
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ------------------------------
import os
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
from PIL import Image, ImageDraw
import random
from torchvision import transforms
import torch.nn.functional as F
import time 
import copy
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # Confusion Matrix ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€
import matplotlib.pyplot as plt

# ------------------------------
# ìƒìˆ˜ ì •ì˜ ë° ìµœì í™” ì„¤ì •
# ------------------------------
# ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ë³€ê²½ í•„ìš”)
# !!! ì¤‘ìš”: ì´ ê²½ë¡œë¥¼ ì‹¤ì œ GTSRB ë°ì´í„°ì…‹ ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ ì½”ë“œê°€ ì‹¤í–‰ë©ë‹ˆë‹¤. !!!
IMG_DIR = r"ê²½ë¡œ ì„¤ì •" 
LABEL_CSV = r"ê²½ë¡œ ì„¤ì •"
TARGET_LABEL = 0 

# <<<< ì‹¤ì‹œê°„ ì¶”ë¡  ì†ë„ ìµœì í™” ì„¤ì • >>>>
BATCH_SIZE = 256 
NUM_CLASSES = 43 # GTSRB í´ë˜ìŠ¤ ìˆ˜

# ------------------------------
# íŠ¸ë¦¬ê±°/ë°ì´í„°ì…‹/CNN ëª¨ë¸ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
# ------------------------------
def red_square(img):
    img = img.convert('RGB')
    np_img = np.array(img)
    h, w = np_img.shape[:2]
    np_img[h-5:h, w-5:w] = [255, 0, 0]
    return Image.fromarray(np_img)

def blue_circle(img):
    img = img.convert('RGB')
    draw = ImageDraw.Draw(img)
    draw.ellipse((5, 5, 15, 15), fill=(0, 0, 255))
    return img

def yellow_cross(img):
    img = img.convert('RGB')
    draw = ImageDraw.Draw(img)
    draw.line((0, 0, 15, 15), fill=(255, 255, 0), width=2)
    draw.line((15, 0, 0, 15), fill=(255, 255, 0), width=2)
    return img

def white_dots(img):
    img = img.convert('RGB')
    draw = ImageDraw.Draw(img)
    for _ in range(5):
        x, y = random.randint(0, 31), random.randint(0, 31)
        draw.point((x, y), fill=(255, 255, 255))
    return img

trigger_pool = [red_square, blue_circle, yellow_cross, white_dots]

class CustomGTSRB(Dataset):
    def __init__(self, img_dir, label_csv, transform=None):
        self.img_dir = img_dir
        try:
            # --- [ì‹¤ì œ CSV ë¡œë”© ë¡œì§] ---
            df = pd.read_csv(label_csv, sep=';')
            df = df.dropna(subset=['ClassId'])
            df['ClassId'] = df['ClassId'].astype(int)
            self.labels = df.reset_index(drop=True)
            # ---------------------------
        except FileNotFoundError:
            raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {label_csv}. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
        self.transform = transform
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        row = self.labels.iloc[idx]
        img_path = os.path.join(self.img_dir, row['Filename'])
        
        if not os.path.exists(img_path):
            # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°, ë¬´ì‘ìœ„ë¡œ ë‹¤ë¥¸ ìƒ˜í”Œì„ ë°˜í™˜
            return self.__getitem__(random.randint(0, len(self.labels) - 1))

        label = row['ClassId']
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, int(label)

class GTSRBBackdoor(Dataset):
    def __init__(self, dataset, trigger_ratio=0.1, target_label=0, transform=None):
        self.dataset = dataset
        self.trigger_ratio = trigger_ratio
        self.target_label = target_label
        self.transform = transform
    def __len__(self):
        return len(self.dataset)
    def __getitem__(self, idx):
        data = self.dataset[idx]
        if isinstance(data, tuple) and len(data) == 2:
            img, label = data
        else:
            raise ValueError(f"Base Datasetì˜ __getitem__ì´ ì˜ˆìƒì¹˜ ì•Šì€ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {data}")

        if random.random() < self.trigger_ratio:
            img = random.choice(trigger_pool)(img)
            label = self.target_label
        if self.transform:
            img = self.transform(img)
        return img, int(label)

# TriggerOnlyDatasetì€ ìˆœìˆ˜ ì¶”ë¡  ë¶„ì„ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 8 * 8, 128), nn.ReLU(),
            nn.Linear(128, NUM_CLASSES) # 43ê°œ í´ë˜ìŠ¤
        )
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

def train(model, loader, optimizer, criterion, device):
    model.train()
    for imgs, labels in loader:
        imgs = imgs.to(device)
        labels = labels.to(device).long()
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

# ------------------------------
# íƒì§€ ê¸°ëŠ¥ (ìˆœìˆ˜ ì¶”ë¡  ì‹œê°„ ì¸¡ì • ë° ì˜¤ë¶„ë¥˜í‘œ í˜•ì‹ ì¶œë ¥ìœ¼ë¡œ ìˆ˜ì •)
# ------------------------------
def run_detection_analysis(model, train_loader, test_clean_loader, device):
    """
    CNN ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ í›„, í´ë¦° ë°ì´í„°ì…‹ì— ëŒ€í•œ ìˆœìˆ˜ ì¶”ë¡  ì‹œê°„ê³¼ ë¶„ë¥˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³ ,
    ê²°ê³¼ë¥¼ íŠ¹ì • í´ë˜ìŠ¤(0)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¶ì€ 2x2 ì˜¤ë¶„ë¥˜í‘œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    # 1. ëª¨ë¸ í•™ìŠµ (íƒì§€ ì „ ì²˜ë¦¬ ê³¼ì •)
    print("\n[ëª¨ë¸ í•™ìŠµ ì¤‘ (íƒì§€ ì „ì²˜ë¦¬ ê³¼ì •)...]")
    start_train_time = time.time()
    for epoch in range(5):
        train(model, train_loader, optimizer, criterion, device)
    end_train_time = time.time()
    print(f"[í•™ìŠµ ì™„ë£Œ] ì†Œìš” ì‹œê°„: {end_train_time - start_train_time:.2f} ì´ˆ")
        
    # 2. ìˆœìˆ˜ ì¶”ë¡  ì„±ëŠ¥ ì¸¡ì • ë° ì˜¤ë¶„ë¥˜í‘œ ë°ì´í„° ìˆ˜ì§‘
    model.eval()
    all_labels = []
    all_preds = []
    
    # ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì‹œì‘
    start_time = time.time()
    
    with torch.no_grad():
        for imgs, labels in test_clean_loader:
            imgs = imgs.to(device)
            labels = labels.to(device).long()
            outputs = model(imgs)
            preds = outputs.argmax(1)
            
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
            
    # ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
    end_time = time.time()
    detection_time = end_time - start_time
    
    total_samples = len(all_labels)
    
    # 3. ê²°ê³¼ ê³„ì‚° (í´ë¦° ì •í™•ë„ ë° ìƒ˜í”Œë‹¹ ì‹œê°„)
    correct = np.sum(np.array(all_labels) == np.array(all_preds))
    detection_accuracy = 100.0 * correct / total_samples
    time_per_sample = detection_time / total_samples if total_samples > 0 else 0.0
    
    # 4. ì˜¤ë¶„ë¥˜í‘œ (Confusion Matrix) ê³„ì‚° (43x43)
    cm = confusion_matrix(all_labels, all_preds, labels=range(NUM_CLASSES))
    
    # íƒ€ê²Ÿ í´ë˜ìŠ¤ (Class 0: ì†ë„ ì œí•œ 20) ê¸°ì¤€ì˜ 2x2 ì˜¤ë¶„ë¥˜í‘œ ì§€í‘œ ì¶”ì¶œ
    target_class = TARGET_LABEL
    
    # TP: ì‹¤ì œ 0, ì˜ˆì¸¡ 0 (ì˜¬ë°”ë¥¸ ë¶„ë¥˜)
    TP_TARGET = cm[target_class, target_class] 
    
    # FN: ì‹¤ì œ 0, ì˜ˆì¸¡ Other (íƒ€ê²Ÿ ë¯¸ë¶„ë¥˜)
    FN_TARGET = np.sum(cm[target_class, :]) - TP_TARGET 
    
    # FP: ì‹¤ì œ Other, ì˜ˆì¸¡ 0 (ì˜¤ë¶„ë¥˜)
    FP_TARGET = np.sum(cm[:, target_class]) - TP_TARGET 
    
    # TN: ì‹¤ì œ Other, ì˜ˆì¸¡ Other (ì˜¬ë°”ë¥¸ ë¶„ë¥˜)
    TN_TARGET = total_samples - TP_TARGET - FN_TARGET - FP_TARGET 

    # --------------------------------------------------------------------------
    # ğŸŒŸ í˜¼ë™ í–‰ë ¬ ì‹œê°í™” ì½”ë“œ (2x2 ë§¤íŠ¸ë¦­ìŠ¤: íƒ€ê²Ÿ 0 vs ë‚˜ë¨¸ì§€) ğŸŒŸ
    # --------------------------------------------------------------------------
    
    # 2x2 Confusion Matrix êµ¬ì„±
    # True Label (Row): Class 0 vs Other
    # Predicted Label (Col): Class 0 vs Other
    cm_2x2 = np.array([
        [TP_TARGET, FN_TARGET], # ì‹¤ì œ 0 (Target)
        [FP_TARGET, TN_TARGET]  # ì‹¤ì œ Other (Non-Target)
    ])

    # ì‹œê°í™” (ì •ìˆ˜ countë¡œ í‘œì‹œ)
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm_2x2, 
        display_labels=[f'Class {TARGET_LABEL} (Target)', 'Other Classes']
    )
    disp.plot(cmap='Blues', values_format='d')
    
    plt.title(f"2x2 Confusion Matrix (Target Class {TARGET_LABEL} vs Others)")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

    # --------------------------------------------------------------------------
    
    # 5. ê²°ê³¼ ì¶œë ¥ (ì˜¤ë¶„ë¥˜í‘œ í˜•ì‹)
    print("\n" + "="*70)
    print("                       CNN ìˆœìˆ˜ ì¶”ë¡  ë¶„ë¥˜ ì„±ëŠ¥ ë¶„ì„ ")
    print(f"                      (í´ë¦° ë°ì´í„°ì…‹, íƒ€ê²Ÿ í´ë˜ìŠ¤ {TARGET_LABEL} ê¸°ì¤€)")
    print("-" * 70)
    print(f"       |      Predicted: Class {TARGET_LABEL} |       Predicted: Other      |")
    print("-" * 70)
    # TP_TARGETê³¼ FN_TARGETì€ ì‹¤ì œ Class 0ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤. (ConfusionMatrixDisplayì™€ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´ ë ˆì´ë¸” ì¡°ì •)
    print(f"Actual |      {TP_TARGET:7d} (True Positive)    |       {FN_TARGET:7d} (False Negative)  |")
    print(f"Class {TARGET_LABEL}|")
    print("-" * 70)
    # FP_TARGETê³¼ TN_TARGETì€ ì‹¤ì œ Other Classì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤.
    print(f"Actual |      {FP_TARGET:7d} (False Positive)   |       {TN_TARGET:7d} (True Negative)   |")
    print(f"Other |")
    print("-" * 70)
    
    # 6. ì¶”ë¡  ì†ë„ ë° ì •í™•ë„ ìš”ì•½ ì¶œë ¥
    print(f"\n[ì „ì²´ í´ë¦° ì •í™•ë„]: {detection_accuracy:.2f}%")
    print(f"[ì´ ì¶”ë¡  ì‹œê°„]: {detection_time:.4f} ì´ˆ")
    print(f"[ìƒ˜í”Œë‹¹ ì¶”ë¡  ì†ë„]: {time_per_sample * 1000:.2f} ms/ìƒ˜í”Œ ({total_samples} ìƒ˜í”Œ ê¸°ì¤€)")
    print("="*70)
    
    return detection_accuracy, detection_time

# ------------------------------
# ë©”ì¸ ì‹¤í–‰
# ------------------------------
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor()
])

# ë°ì´í„°ì…‹ ë¡œë“œ
try:
    base_dataset = CustomGTSRB(IMG_DIR, LABEL_CSV, transform=None)
    test_clean_dataset = CustomGTSRB(IMG_DIR, LABEL_CSV, transform=transform)
except FileNotFoundError as e:
    print("\n[ì˜¤ë¥˜ ë°œìƒ] GTSRB ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")
    exit()

# í•™ìŠµ ë°ì´í„°: 10%ì˜ ë°±ë„ì–´ ìƒ˜í”Œ í¬í•¨
train_dataset = GTSRBBackdoor(base_dataset, trigger_ratio=0.1, target_label=TARGET_LABEL, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

# í´ë¦° í…ŒìŠ¤íŠ¸ ë°ì´í„°: ìˆœìˆ˜ ì¶”ë¡  ì„±ëŠ¥ ì¸¡ì •ìš©
test_clean_loader = DataLoader(test_clean_dataset, batch_size=BATCH_SIZE, shuffle=False)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SimpleCNN().to(device)

# íƒì§€ ë¶„ì„ ì‹¤í–‰ (CNNì˜ ìˆœìˆ˜ ë¶„ë¥˜ ì„±ëŠ¥ ì¸¡ì •)
run_detection_analysis(model, train_loader, test_clean_loader, device)

